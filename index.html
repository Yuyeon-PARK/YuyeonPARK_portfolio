<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Yuyeon PARK - Welcome to my web!</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.4/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Yuyeon PARK</span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#Courses">Courses</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        PARK
                        <span class="text-primary">Yuyeon</span>
                    </h1>
                    <div class="subheading mb-5">
                        +82-10-2527-5997 ·
                        <a href="mailto:name@email.com">puyoun@gmail.com</a>
                    </div>
                    <p class="lead mb-5">Statistician, Data Scientist, Now Data Analyst</p>
                    <div class="social-icons">
                        <a class="social-icon" href="https://www.linkedin.com/in/yuyeon-park-89925822b/"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/Yuyeon-PARK"><i class="fab fa-github"></i></a>
                        <a class="social-icon" href="https://dspace.ewha.ac.kr/handle/2015.oak/264318"><i class="fab fa-graduation-cap"></i></a>
                    </div>
                </div>
            </section>
            <hr class="m-0" />           
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Ewha Womans University</h3>
                            <div class="subheading mb-3">Master of Science</div>
                            <div>Applied Statistics</div>
                            <p>GPA: 4.1/4.3</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2021 - Feburary 2023</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Ewha Womans University</h3>
                            <div class="subheading mb-3">Bachelor of Science, Bachelor of Arts</div>
                            <div>Statistics, Christian Studies</div>
                            <p>GPA: 3.45/4.3</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2016 - Feburary 2021</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Projects-->
            <section class="resume-section" id="Projects">
                <div class="resume-section-content">
                    <h2 class="mb-5">Projects</h2>
                    <h3 class="mb-2">Graduate School</h3>
                    
                        <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Selected Topics in Data Analysis I </h3>
                            <h5 class="mb-0">category: Functional Data Analysis </h5>
                            <h5 class="mb-0">tools: R</h5>
                            <div class="subheading mb-3">Final project : Spatial Functional Data Analysis using K-Means Clustering</div>
                            <p>It was an individual project. This project aims to analyze and predict the monthly traffic volumes at both entrance and exit of Daejeon IC using the information including locations and the traffic volumes of 343 ICs in August 2021. In this paper, there are three steps to analyze functional data: 1) Making data as a functional form using Fourier basis, 2) Clustering formed data into 6 clusters through K-Means algorithm, 3) Predicting the traffic volumes of unobserved point, Daejeon IC, using kriging. </p>
                            <p>For the entrance prediction, the estimated value is similar to the true value, on the contrary, the exit prediction could not estimate well. There are two possibilities of failure: 1) If in the resampling step, the extracted data could not represent the characteristics of each cluster, 2) If each cluster’s lengths are significantly different. Therefore, the failure of prediction in the exit might be from those two reasons.</p>
                            <img src="자분특1.jpg",width="250" height="310"><img src="자분특2.jpg",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2022 - June 2022</span></div>
                    </div>
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Advanced Topics in Contemporary Statistcs</h3>
                            <h5 class="mb-0">category: Deep learning, LSTM, Auto-Encoder, Variational Auto-Encoder </h5>
                            <h5 class="mb-0">tools: Python</h5>
                            <div class="subheading mb-3">Final project : Anomaly Detection of Time Series using Autoencoder, Variational Autoencoder, and with combining LSTM</div>
                            <p>It was the individual project. This project aims to analyze and predict the anomaly of sequence of PM10 during 2021. In this paper, there are four methods to analyze PM10 data: 1) Autoencoder, 2) Variational Autoencoder, 3) LSTM-Autoencoder, 4) LSTM-Variational Autoencoder. Among those four methods, LSTM-Autoencoder performed best in terms of accuracy.</p>
                            <p>For analyzing the trend of PM10, dataset consisted with various variables will be used in this project. Every data was collected same point, Jung-gu, Seoul. The explanations of each variable are here. There are 15 multivariate variables as X, and PM10 used as Y variable. In this data, the NA values were filled with 0 because almost blanks means there were no weather events.</p>
                            <p>The experiments were conducted through four methodologies: Autoencoder, Variational Autoencoder, LSTM-Autoencoder, LSTM-Variational Autoencoder.</p>
                            <p>Autoencoder consists of two parts, encoder, and decoder. It works with those processes: 1) Input data to an encoder with several layers, 2) After encoding, the result of encoding is put to the decoder using Repeatvector in Keras, 3) After decoding, the reconstructed data would be made, then compare the estimated data with real data.</p>
                            <p>Similarly, Variational Autoencoder works with a process with four steps, but between step 2) and step 3), the latent dimension has to be added. In other words, a latent variable assigned to the Gaussian distribution would be made after encoding. Then inputting those variables into the decoder makes the reconstructed data.</p>
                            <p>LSTM AE and LSTM VAE also follow similar flows to those models that do not relate to LSTM layers. In those two models, LSTM AE and LSTM VAE, use LSTM layers instead of vanilla denses used above. For using LSTM, it is necessary to stack the last layer with Time-distributed because LSTM is designed for analyzing the temporal sequence.
Those four models not only do dimension reduction but also reconstruct data as similar as possible. In this regard, it is meaningful to compare those models’ performances for finding out the best model.
</p>
                            <p>Overall, the performances of each model are not good than expected. There are two possibilities of failure: 1) This project conducted in multivariate way, even without PM10 in X variables. In other words, the kind of the variables could deconcentrate whole data. If PM10 data was used only, then that could make better performances than now. In addition, PM10 is a weather data, that means it could be affected by various factors. However, the anomaly detection in machines does not contain the risk of being affected by those factors. That is the biggest differences of related papers and this project. 2) There were not enough time and devices to analyze it in infinite way. If GPU conducted this experiment, then it could allow us to earn much of times to analyze it.
Although, the LSTM-AE model performed well among those four models in terms of accuracy, and if modify the LSTM-AE model in various way, the performance could be improved. In the perspective of recall for abnormal values, VAE and LSTM-VAE model performed well similarly. Therefore, the models with latent space could find anomalies well. 
</p>
                            <img src="고통1_lstm_ae_loss.png",width="250" height="310"><img src="고통2_anomaly_lstm_ae.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2021 - December 2021</span></div>
                    </div>
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Economic Data Analysis</h3>
                            <h5 class="mb-0">category: ARIMA, ADL, VAR</h5>
                            <h5 class="mb-0">tools: R</h5>
                            <div class="subheading mb-3">Final Project : Prediction of Economic Time Series Data </div>
                            <p>It was an individual project to predict the price elasticity of demand. I analyzed wheat gross production values in the U.S. and U.S. - foreign wheat price, dollars per metric ton yearly data for the last 56 years. For the first, I defined “Domestic disappearance million metrics tons” as a variable named “Demand”, which means demanded amount of wheat in the U.S., “Price of wheat in current USD” as “Price”. In addition, I used CPI from the USA CPI in 2010 as 100. I used ARMIA, ADL, and VAR model to predict wheat price.
Thus, it was purposed to analyze the price elasticity of domestic demand between “Demand” and “Price” in the USA. The USA is one of the biggest wheat-production countries, and consume wheat as their daily meal. Therefore, it is important to find the effect of the wheat demand on its price for forecasting consumers’ consumption behavior. Also, the Russia-Ukraina Invasion in February 2021 caused pricing fluctuation all over the world including wheat. Wheat consumption has increased year over year so it has been necessary to manage the production volume of wheat in the USA. This research and analysis could suggest how to secure wheat stably in the near future.
</p>
                            <img src="경자분1.png",width="250" height="310"><img src="경자분2.png",width="250" height="310"><img src="경자분3.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2022 - June 2022</span></div>
                    </div>
                    
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Data Mining</h3>
                            <h5 class="mb-0">category: Machine Learning</h5>
                            <h5 class="mb-0">tools: R, Python</h5>
                            <div class="subheading mb-3">Final project : Classification of Fetal health using ML Methodologies</div>
                            <p>It was a team project using various ML methodologies with fetal heart rate and uterine activity data to classify fetal health conditions in 3 levels; Normal, Suspect, and Pathologic. For determining the “Suspect” status, we used Machine Learning Classification such as Decision Tree, Random Forest, Support Vector Classifier, Support Vector Machine, Xgboost, and KNN. To decide the best model for finding the suspicious status of the fetus, we used 3 different types of evaluation thresholds: Accuracy, ROC, and Time. Decision Tree spent the shortest time among those methodologies but accuracy was low. Random Forest spent about 16 sec for learning and testing, and also had high accuracy. SVC had the lowest accuracy and needed about 1 minute for modeling. SVM had the 2nd highest accuracy but took the longest time for modeling. Xgboost and KNN spent reasonable time modeling and had greater accuracy than Decision Tree and SVC. Even Xgboost had the highest accuracy among those methodologies.</p>
                            <img src="데마1.png",width="250" height="310"><img src="데마2.png",width="250" height="310"><img src="데마3.jpg",width="250" height="310"><img src="데마4.jpg",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2022 - June 2022</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Computational Statistics</h3>
                            <h5 class="mb-0">category: algoritm</h5>
                            <h5 class="mb-0">tools: R, Python</h5>
                            <div class="subheading mb-3">Final project : N-queens problem</div>
                            <p>It was a team project. We created an algorithm to find a solution to the N-queens problem using a local search and optimization, Simulated Annealing, Hill Climbing, and Local Beam Search. We compared their performances in accuracy and running time. I found that Simulated Annealing and Local Beam Search were superior in performance, but took a long time to calculate solutions via python.</p>
                            <img src="compstat.png",width="250" height="310"><img src="compstat1.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2021 - December 2021</span></div>
                    </div>
                
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Generalized Linear Model</h3>
                            <h5 class="mb-0">category: Deep learning</h5>
                            <h5 class="mb-0">tools: Python, tensorflow, keras</h5>
                            <div class="subheading mb-3">Final project : Prices of Apartments in Seoul</div>
                            <p>It was a team project, and I was the leader. Rather than using traditional GLM based models, we used the deep learning methodologies LSTM, CNN-LSTM, and GRU to predict time series data. I compared their performance and suggested future areas of research in the prediction of apartment pricing data. We made several important conclusions from the project, namely: 1) LSTM and GRU have similar performances in time series data, 2) confirmed the results of a number of previous papers in this topic area, and 3) identified the most important variables for predicting results with apartment pricing data.</p>
                            <img src="pricing.png",width="200" height="250"><img src="Seocho-total.png",width="200" height="250">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2021 - December 2021</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Big contest</h3>
                            <h5 class="mb-0">category: Deep learning, ARIMA</h5>
                            <h5 class="mb-0">tools: Python, tensorflow, keras, R</h5>
                            <div class="subheading mb-3"></div>
                            <p>It was a team project, and I was the leader. We analyzed weather data using the deep learning methodologies LSTM and CNN-LSTM, as well as ARIMA. Also, I constructed a model to reduce MSE and accurately predict a monthly weather data result. We used logistic variable selection before replacing outliers and finding a correlation between variables. Overall, we discovered CNN-LSTM's performance was superior to the other methodologies.</p>
                            <img src="bigcon.png",width="200" height="250"><img src="bigcon2.jpg",width="200" height="250">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2021 - November 2021</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Samsung Card Idea Challenge</h3>
                            <h5 class="mb-0">category: Deep learning, NLP(Natural Language Processing)</h5>
                            <h5 class="mb-0">tools: Python</h5>
                            <p>It was a team project, and I was the leader. We used text mining, a NLP method, to classify and categorize Korean customer survey data. We used emotion analysis and LDA (Latent Dirichlet Allocation).</p>
                            <div class="subheading mb-3"></div>
                            <img src="wordcloud.png",width="180" height="220">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2021 - July 2021</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Statistical Seminar</h3>
                            <h5 class="mb-0">category: Research, Basic Statistical performance</h5>
                            <h5 class="mb-0">tools: R, Python</h5>
                            <div class="subheading mb-3">Final project : Analyze the tendency</div>
                            <p>It was an individual project. I researched GDP and the ratio of education in Humanities. I used the individual internet usage ratio as an instrumental variable. I made several important conclusions from the project, namely: 1) GDP and the individual internet usage have a meaningful relationship so that the government can make efficient ODA policies for developing countries, 2) the ratio of education in Humanities was not higher than expected, so it could be used as basis to widen its area. </p>
                            <img src="ss.png",width="250" height="310"><img src="ss2.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">May 2021 - June 2021</span></div>
                    </div>
                    
                    <h3 class="mb-2">Undergraduate School</h3>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Categorical Data Analysis</h3>
                            <h5 class="mb-0">category: Categorical data analysis</h5>
                            <h5 class="mb-0">tools: R</h5>
                            <div class="subheading mb-3">Final project : Regression analysis, Research </div>
                            <p>It was an individual project. I researched how the internet usage ratio affects poverty in over 256+ countries. I used linear, logistic, probit models. I used the ratio of post-secondary education, GNI, and female first marriage age as additional variables. I made several important conclusions from the project, namely: 1) it could explain the relationship between education level and internet distribution rate, 2) since the pandemic arose, it could be a basis of making policies for post-pandemic preparation.</p>
                            <img src="cate.png",width="250" height="310"><img src="cate2.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">October 2020 - December 2020</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">OIBC data contest</h3>
                            <h5 class="mb-0">category: ARIMA, time series</h5>
                            <h5 class="mb-0">tools: R</h5>
                            <p>It was a team project, and I was the leader. We predicted the amount of solar power generation in 3 days by analyzing seasonal tendency and used ARIMA to make predictions. </p>
                            <img src="pic1.jpg",width="250" height="310"><img src="pic2.png",width="300" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2020 - August 2020</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">International Humanitarian Assistance and Development Cooperation</h3>
                            <h5 class="mb-0">category: Regression Analysis</h5>
                            <h5 class="mb-0">tools: R, Excel</h5>
                            <div class="subheading mb-3">Final project : Regression analysis, Research </div>
                            <p>It was an individual project. I researched the relationship between internet usage and educational states in over 200+ countries and used linear regression. It became a basis of two projects in a Categorical variable course and a Statistical seminar course.</p>
                            <img src="excel1.png",width="200" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2020 - May 2020</span></div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Sampling Survey Methods</h3>
                            <h5 class="mb-0">category: Sampling, categorize</h5>
                            <h5 class="mb-0">tools: R, Excel</h5>
                            <div class="subheading mb-3">Final project : Survey </div>
                            <p>It was a team project. We used population mean, variance, and its ratio to analyze correlation between the cost of the means of communication and the telephone agency. We made several important conclusions from the project that among 118+ students in Ewha Womans University, namely: 1) 79% of students do not pay the cost themselves, 2) each telephone agency has similar percentages regardless of its cost scale.</p>
                            <img src="11.png",width="200" height="250"><img src="22.png",width="250" height="310">
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">October 2018 - December 2018</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
             <!-- Courses-->
             <section class="resume-section" id="Courses">
                <div class="resume-section-content">
                    <h2 class="mb-5">Courses</h2>
                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Graduate school</h3>
                            <p>Economic Data Analysis</p>
                            <p>Data Mining</p>
                            <p>Selected Topics in Data Analysis I : FDA(Functional Data Analysis), STDA(Spatio-Temporal Data Analysis)</p>
                            <p>Advanced Topics in Contemporary Statistics II : Generative Model and Deep Learning</p>
                            <p>Topics in Statistical Computing I : Computational Statistics, Algorithm</p>
                            <p>Generalized Linear Model </p>
                            <p>Bayesian Statistics </p> 
                            <p>Probability Theory I </p>
                            <p>Regression Analysis </p>
                            <p>Theoretical Statistics I </p>
                            <p>Seminar in Statistics II </p>
                        </div>
                    </div>
                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Undergraduate school</h3>
                            <p>Categorical Data Analysis </p>
                            <p>Data Mining </p>
                            <p>Analysis of Life Science Data </p>
                            <p>Introduction to Time Series Analysis </p>
                            <p>Programming for Statistics : VBA, Python</p>
                            <p>Computational Statistics and Lab : SAS </p>
                            <p>Mathematical Statistics I,II </p>
                            <p>Sampling Survey Method</p>
                            <p>Regression Analysis </p>
                            <p>Basic Probability Theory </p>
                            <p>Basic Statistics </p>
                            
                        </div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content">
                    <h2 class="mb-5">Skills</h2>
                    <div class="subheading mb-3">Programming Languages & Tools</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item"><i class="fab fa-r-project"></i></li>
                        <li class="list-inline-item"><i class="fab fa-python"></i></li>
                        <li class="list-inline-item"><i class="fas fa-database"></i></li>
                        <p>SAS, VBA</p>

                    </ul>
                    <div class="subheading mb-3">Workflow</div>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Functional Data Analysis
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Deep Learning
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Machine Learning
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Datamining
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            Regression Analysis
                        </li>

                    </ul>
                    <div class="subheading mb-3">Certification</div>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            SQLD(SQL Developer)
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            ADsP(Advanced Data Analytics Semi-Professional)
                        </li>
                    </ul>
                </div>
            </section>
            <hr class="m-0" />
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
